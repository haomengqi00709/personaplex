<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PersonaPlex å®æ—¶ç¿»è¯‘</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }
        .container {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
        }
        button {
            padding: 10px 20px;
            margin: 10px 5px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            background: #4CAF50;
            color: white;
        }
        button:hover {
            background: #45a049;
        }
        button.recording {
            background: #f44336;
        }
        select {
            padding: 8px;
            margin: 10px 5px;
            font-size: 14px;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            background: #e0e0e0;
            border-radius: 5px;
        }
    </style>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
</head>
<body>
    <div class="container">
        <h1>PersonaPlex å®æ—¶ç¿»è¯‘</h1>
        
        <div class="status" id="status">çŠ¶æ€: æœªè¿æ¥</div>
        
        <div>
            <button id="loadModelBtn">åŠ è½½æ¨¡å‹</button>
            <span id="modelStatus"></span>
        </div>
        
        <div style="margin: 20px 0;">
            <label>æºè¯­è¨€:</label>
            <select id="sourceLang">
                <option value="en">è‹±è¯­</option>
                <option value="zh">ä¸­æ–‡</option>
            </select>
            
            <label>ç›®æ ‡è¯­è¨€:</label>
            <select id="targetLang">
                <option value="zh">ä¸­æ–‡</option>
                <option value="en">è‹±è¯­</option>
            </select>
        </div>
        
        <div>
            <button id="recordBtn">ğŸ™ï¸ å¼€å§‹å½•éŸ³</button>
        </div>
        
        <div id="output" style="margin-top: 20px; padding: 10px; background: white; border-radius: 5px; min-height: 100px;">
            <p>ç¿»è¯‘ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...</p>
        </div>
    </div>

    <script>
        const socket = io();
        let isRecording = false;
        let audioContext = null;
        let processor = null;
        let stream = null;
        let audioChunks = [];
        let sendInterval = null;

        // Socket.IO è¿æ¥
        socket.on('connect', () => {
            document.getElementById('status').textContent = 'çŠ¶æ€: å·²è¿æ¥';
        });

        socket.on('disconnect', () => {
            document.getElementById('status').textContent = 'çŠ¶æ€: æœªè¿æ¥';
        });

        socket.on('translated_audio', (data) => {
            // æ’­æ”¾ç¿»è¯‘åçš„éŸ³é¢‘
            const audio = new Audio('data:audio/wav;base64,' + data.audio);
            audio.play();
        });

        // åŠ è½½æ¨¡å‹
        async function loadModel() {
            try {
                const response = await fetch('/api/load_model', { method: 'POST' });
                const result = await response.json();
                document.getElementById('modelStatus').textContent = result.message;
            } catch (error) {
                console.error('åŠ è½½æ¨¡å‹å¤±è´¥:', error);
            }
        }

        // å¼€å§‹å½•éŸ³
        async function startRecording() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                const source = audioContext.createMediaStreamSource(stream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioChunks = [];
                
                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioChunks.push(new Float32Array(inputData));
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                // å®šæœŸå‘é€éŸ³é¢‘æ•°æ®
                sendInterval = setInterval(() => {
                    if (audioChunks.length > 0) {
                        // åˆå¹¶éŸ³é¢‘å—
                        const totalLength = audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
                        const merged = new Float32Array(totalLength);
                        let offset = 0;
                        for (const chunk of audioChunks) {
                            merged.set(chunk, offset);
                            offset += chunk.length;
                        }
                        audioChunks = [];
                        
                        // è½¬æ¢ä¸º WAV
                        const wavBuffer = audioBufferToWav({
                            numberOfChannels: 1,
                            length: merged.length,
                            sampleRate: 24000,
                            getChannelData: (ch) => {
                                if (ch === 0) return merged;
                                return new Float32Array(merged.length);
                            }
                        });
                        
                        // è½¬æ¢ä¸ºæ•°ç»„å¹¶å‘é€
                        const uint8Array = new Uint8Array(wavBuffer);
                        const audioArray = Array.from(uint8Array);
                        
                        // éªŒè¯æ–‡ä»¶å¤´
                        if (audioArray.length >= 4) {
                            const headerStr = String.fromCharCode(
                                audioArray[0], audioArray[1], audioArray[2], audioArray[3]
                            );
                            console.log('å‡†å¤‡å‘é€éŸ³é¢‘ï¼Œæ–‡ä»¶å¤´:', headerStr, 'å¤§å°:', audioArray.length);
                            
                            if (headerStr === 'RIFF') {
                                const sourceLang = document.getElementById('sourceLang').value;
                                const targetLang = document.getElementById('targetLang').value;
                                
                                console.log('å‘é€éŸ³é¢‘æ•°æ®ï¼Œæ•°ç»„é•¿åº¦:', audioArray.length);
                                socket.emit('audio_chunk', {
                                    audio: audioArray,
                                    source_lang: sourceLang,
                                    target_lang: targetLang
                                });
                            } else {
                                console.error('éŸ³é¢‘æ–‡ä»¶å¤´æ— æ•ˆ:', headerStr);
                            }
                        } else {
                            console.error('éŸ³é¢‘æ•°æ®å¤ªçŸ­:', audioArray.length);
                        }
                    }
                }, 3000);
                
                isRecording = true;
                document.getElementById('recordBtn').textContent = 'â¹ï¸ åœæ­¢å½•éŸ³';
                document.getElementById('recordBtn').classList.add('recording');
                
            } catch (error) {
                console.error('å½•éŸ³å¤±è´¥:', error);
                alert('æ— æ³•è®¿é—®éº¦å…‹é£: ' + error.message);
            }
        }

        // åœæ­¢å½•éŸ³
        function stopRecording() {
            if (isRecording) {
                if (processor) processor.disconnect();
                if (stream) stream.getTracks().forEach(track => track.stop());
                if (audioContext) audioContext.close();
                if (sendInterval) clearInterval(sendInterval);
                
                isRecording = false;
                document.getElementById('recordBtn').textContent = 'ğŸ™ï¸ å¼€å§‹å½•éŸ³';
                document.getElementById('recordBtn').classList.remove('recording');
            }
        }

        // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º WAV
        function audioBufferToWav(buffer) {
            const numOfChan = buffer.numberOfChannels || 1;
            const sampleRate = buffer.sampleRate || 24000;
            const length = buffer.length;
            const dataLength = length * numOfChan * 2;
            const arrayBuffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(arrayBuffer);
            let pos = 0;

            const setUint16 = (data) => {
                view.setUint16(pos, data, true);
                pos += 2;
            };
            const setUint32 = (data) => {
                view.setUint32(pos, data, true);
                pos += 4;
            };

            // WAV æ–‡ä»¶å¤´
            setUint32(0x46464952); // "RIFF"
            setUint32(36 + dataLength);
            setUint32(0x45564157); // "WAVE"
            setUint32(0x20746d66); // "fmt "
            setUint32(16);
            setUint16(1); // PCM
            setUint16(numOfChan);
            setUint32(sampleRate);
            setUint32(sampleRate * 2 * numOfChan);
            setUint16(numOfChan * 2);
            setUint16(16);
            setUint32(0x61746164); // "data"
            setUint32(dataLength);

            // å†™å…¥ PCM æ•°æ®
            const channelData = buffer.getChannelData(0);
            for (let i = 0; i < length; i++) {
                let sample = Math.max(-1, Math.min(1, channelData[i]));
                sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                view.setInt16(pos, sample, true);
                pos += 2;
            }

            return arrayBuffer;
        }

        // äº‹ä»¶ç›‘å¬
        document.getElementById('loadModelBtn').addEventListener('click', loadModel);
        document.getElementById('recordBtn').addEventListener('click', () => {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        });
    </script>
</body>
</html>
